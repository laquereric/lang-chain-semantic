{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraphSemantic Demo Notebook\n",
    "\n",
    "This notebook demonstrates the integration of Pydantic models with SHACL shapes in RDF stores using the LangGraphSemantic library. It shows how to connect LangChain and LangGraph with semantic data validation and storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "import requests\n",
    "\n",
    "# Import LangGraphSemantic\n",
    "from langgraphsemantic import LangGraphSemantic\n",
    "from langgraphsemantic.core import ShapeGenerator\n",
    "from langgraphsemantic.store import FusekiStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Fuseki Connection\n",
    "\n",
    "Let's make sure our Fuseki server is running and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define Fuseki connection parameters\n",
    "FUSEKI_URL = \"http://fuseki:3030\"\n",
    "DATASET = \"langgraphsemantic\"\n",
    "\n",
    "# Check if Fuseki is running\n",
    "def check_fuseki():\n",
    "    try:\n",
    "        response = requests.get(FUSEKI_URL)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Fuseki server is running.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Fuseki server returned status code {response.status_code}.\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Could not connect to Fuseki server.\")\n",
    "        return False\n",
    "\n",
    "# Check if dataset exists\n",
    "def check_dataset():\n",
    "    try:\n",
    "        response = requests.get(f\"{FUSEKI_URL}/$/datasets\")\n",
    "        if response.status_code == 200:\n",
    "            datasets = response.json()\n",
    "            if any(ds[\"ds.name\"] == DATASET for ds in datasets[\"datasets\"]):\n",
    "                print(f\"Dataset '{DATASET}' exists.\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Dataset '{DATASET}' does not exist.\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"Failed to get datasets: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create dataset if it doesn't exist\n",
    "def create_dataset():\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{FUSEKI_URL}/$/datasets\",\n",
    "            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "            data=f\"dbName={DATASET}&dbType=tdb\"\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Dataset '{DATASET}' created successfully.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to create dataset: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check and setup Fuseki\n",
    "if check_fuseki():\n",
    "    if not check_dataset():\n",
    "        create_dataset()\n",
    "else:\n",
    "    print(\"Please make sure the Fuseki server is running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pydantic Models\n",
    "\n",
    "Let's define some Pydantic models that we'll use to demonstrate the LangGraphSemantic library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class Address(BaseModel):\n",
    "    \"\"\"A physical address.\"\"\"\n",
    "    street: str\n",
    "    city: str\n",
    "    state: str = Field(..., min_length=2, max_length=2)\n",
    "    zip_code: str = Field(..., regex=r'^\\d{5}(-\\d{4})?$')\n",
    "    country: str = Field(default=\"US\")\n",
    "    \n",
    "    @validator('state')\n",
    "    def state_must_be_uppercase(cls, v):\n",
    "        if not v.isupper():\n",
    "            raise ValueError('State code must be uppercase')\n",
    "        return v\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"A person with contact information.\"\"\"\n",
    "    id: str\n",
    "    name: str = Field(..., min_length=1)\n",
    "    age: int = Field(..., ge=0, lt=150)\n",
    "    email: Optional[str] = None\n",
    "    addresses: List[Address] = []\n",
    "    tags: List[str] = []\n",
    "    \n",
    "    @validator('email')\n",
    "    def email_must_contain_at(cls, v):\n",
    "        if v is not None and '@' not in v:\n",
    "            raise ValueError('Email must contain @')\n",
    "        return v\n",
    "\n",
    "# Create some example instances\n",
    "address1 = Address(\n",
    "    street=\"123 Main St\",\n",
    "    city=\"San Francisco\",\n",
    "    state=\"CA\",\n",
    "    zip_code=\"94105\"\n",
    ")\n",
    "\n",
    "address2 = Address(\n",
    "    street=\"456 Market St\",\n",
    "    city=\"San Francisco\",\n",
    "    state=\"CA\",\n",
    "    zip_code=\"94105\"\n",
    ")\n",
    "\n",
    "person1 = Person(\n",
    "    id=\"p1\",\n",
    "    name=\"John Doe\",\n",
    "    age=30,\n",
    "    email=\"john.doe@example.com\",\n",
    "    addresses=[address1, address2],\n",
    "    tags=[\"developer\", \"python\"]\n",
    ")\n",
    "\n",
    "person2 = Person(\n",
    "    id=\"p2\",\n",
    "    name=\"Jane Smith\",\n",
    "    age=28,\n",
    "    email=\"jane.smith@example.com\",\n",
    "    addresses=[address1],\n",
    "    tags=[\"manager\", \"product\"]\n",
    ")\n",
    "\n",
    "print(f\"Created example models: {person1.name} and {person2.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LangGraphSemantic\n",
    "\n",
    "Now let's initialize the LangGraphSemantic library and connect it to our Fuseki server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize LangGraphSemantic\n",
    "semantic = LangGraphSemantic(\n",
    "    fuseki_url=FUSEKI_URL,\n",
    "    dataset=DATASET,\n",
    "    base_namespace=\"http://example.org/\"\n",
    ")\n",
    "\n",
    "print(\"LangGraphSemantic initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Models and Generate SHACL Shapes\n",
    "\n",
    "Let's register our Pydantic models with LangGraphSemantic, which will generate SHACL shapes for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Register models\n",
    "print(\"Registering Address model...\")\n",
    "address_registered = semantic.register_model(Address)\n",
    "print(f\"Address model registered: {address_registered}\")\n",
    "\n",
    "print(\"\\nRegistering Person model...\")\n",
    "person_registered = semantic.register_model(Person)\n",
    "print(f\"Person model registered: {person_registered}\")\n",
    "\n",
    "# Get the generated SHACL shapes\n",
    "address_shape = semantic.store.get_shape(\"Address\")\n",
    "person_shape = semantic.store.get_shape(\"Person\")\n",
    "\n",
    "print(\"\\nAddress SHACL Shape:\")\n",
    "print(address_shape.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"\\nPerson SHACL Shape:\")\n",
    "print(person_shape.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store and Validate Instances\n",
    "\n",
    "Now let's store our model instances in the RDF store and validate them against the SHACL shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Store instances\n",
    "print(\"Storing person1...\")\n",
    "person1_stored = semantic.store_instance(person1)\n",
    "print(f\"Person1 stored: {person1_stored}\")\n",
    "\n",
    "print(\"\\nStoring person2...\")\n",
    "person2_stored = semantic.store_instance(person2)\n",
    "print(f\"Person2 stored: {person2_stored}\")\n",
    "\n",
    "# Validate instances\n",
    "print(\"\\nValidating person1...\")\n",
    "person1_validation = semantic.validate_instance(person1)\n",
    "print(f\"Person1 validation: {person1_validation}\")\n",
    "\n",
    "print(\"\\nValidating person2...\")\n",
    "person2_validation = semantic.validate_instance(person2)\n",
    "print(f\"Person2 validation: {person2_validation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Invalid Instance\n",
    "\n",
    "Let's create an invalid instance to see how validation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    # This should fail Pydantic validation\n",
    "    invalid_address = Address(\n",
    "        street=\"789 Broadway\",\n",
    "        city=\"New York\",\n",
    "        state=\"ny\",  # Should be uppercase\n",
    "        zip_code=\"10001\"\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"Pydantic validation error: {e}\")\n",
    "\n",
    "# Let's create an invalid instance by modifying a valid one\n",
    "# This bypasses Pydantic validation but should fail SHACL validation\n",
    "invalid_person = person1.copy()\n",
    "invalid_person.age = -5  # Age should be >= 0\n",
    "\n",
    "# Store and validate the invalid instance\n",
    "print(\"\\nStoring invalid person...\")\n",
    "invalid_stored = semantic.store_instance(invalid_person)\n",
    "print(f\"Invalid person stored: {invalid_stored}\")\n",
    "\n",
    "print(\"\\nValidating invalid person...\")\n",
    "invalid_validation = semantic.validate_instance(invalid_person)\n",
    "print(f\"Invalid person validation: {invalid_validation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with LangChain\n",
    "\n",
    "Now let's demonstrate how to integrate LangGraphSemantic with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Create a semantic memory component\n",
    "semantic_memory = semantic.create_memory()\n",
    "\n",
    "# Create a semantic retriever\n",
    "semantic_retriever = semantic.create_retriever()\n",
    "\n",
    "# Define a simple LangChain chain that uses semantic memory\n",
    "prompt_template = \"\"\"You are an assistant that helps with managing contact information.\n",
    "The following people are in the database:\n",
    "{semantic_memory}\n",
    "\n",
    "User question: {question}\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"semantic_memory\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "# Note: In a real application, you would use an actual LLM here\n",
    "# For this demo, we'll just simulate the LLM response\n",
    "class MockLLM:\n",
    "    def __call__(self, prompt):\n",
    "        return \"I found John Doe and Jane Smith in the database. John is a developer and Jane is a manager.\"\n",
    "\n",
    "mock_llm = MockLLM()\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=mock_llm,\n",
    "    prompt=prompt,\n",
    "    memory=semantic_memory\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = chain.run(question=\"Who is in the database?\")\n",
    "print(\"LangChain response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the RDF Store\n",
    "\n",
    "Let's demonstrate how to query the RDF store directly using SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Query all people in the store\n",
    "query = \"\"\"\n",
    "SELECT ?person ?name ?age ?email\n",
    "WHERE {\n",
    "  GRAPH ?g {\n",
    "    ?person a <http://example.org/Person> ;\n",
    "            <http://example.org/name> ?name ;\n",
    "            <http://example.org/age> ?age .\n",
    "    OPTIONAL { ?person <http://example.org/email> ?email }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "results = semantic.store.query.execute_select(query)\n",
    "\n",
    "print(\"People in the RDF store:\")\n",
    "for result in results:\n",
    "    print(f\"Person: {result['name']}\")\n",
    "    print(f\"  Age: {result['age']}\")\n",
    "    print(f\"  Email: {result.get('email', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the LangGraphSemantic library to:\n",
    "\n",
    "1. Convert Pydantic models to SHACL shapes\n",
    "2. Store and validate model instances in an RDF store\n",
    "3. Integrate with LangChain for semantic memory and retrieval\n",
    "4. Query the RDF store using SPARQL\n",
    "\n",
    "This provides a powerful foundation for building semantically-aware applications with LangChain and LangGraph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
